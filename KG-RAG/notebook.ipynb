{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from google.oauth2 import service_account\n",
    "from llama_index.llms.vertex import Vertex\n",
    "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "     input_files=[\"data/Graph_Retrieval-Augmented_Generation_A_Survey.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"credentials.json\"\n",
    "credentials: service_account.Credentials = (\n",
    "    service_account.Credentials.from_service_account_file(filename)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Vertex(\n",
    "        model=\"gemini-pro\", \n",
    "        project=credentials.project_id, credentials=credentials\n",
    "    )\n",
    "    \n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = VertexTextEmbedding(\n",
    "    model_name=\"textembedding-gecko@003\",\n",
    "    project=credentials.project_id, credentials=credentials\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store, persist_dir=\"./storage\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=3,\n",
    "    storage_context=storage_context,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## What is Graph Retrieval-Augmented Generation (GraphRAG)?\n",
       "\n",
       "Graph Retrieval-Augmented Generation (GraphRAG) is a novel approach that combines the strengths of large language models (LLMs) and graph data to enhance the performance of various downstream tasks. It leverages the powerful natural language processing capabilities of LLMs to generate high-quality responses while utilizing the rich knowledge and relationships embedded in graph data to improve the accuracy and relevance of the generated content.\n",
       "\n",
       "Here are some key points about GraphRAG:\n",
       "\n",
       "* **It combines graph foundation models with knowledge retrieval.** This allows GraphRAG to leverage the strengths of both approaches, resulting in improved performance on a variety of tasks.\n",
       "* **It is a powerful tool for a variety of downstream tasks.** These include question answering, commonsense reasoning, information retrieval, and others.\n",
       "* **It is a survey of existing methods and techniques for graph retrieval-augmented generation.** This means that it provides an overview of the current state of the art in this field, including different approaches to retrieval, generation enhancement, and downstream tasks.\n",
       "\n",
       "If you would like to learn more about GraphRAG, I recommend reading the survey paper that I have provided a link to in the context information.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True, \n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What is Graph Retrieval-Augmented Generation?\",\n",
    ")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Query-Focused Summarization (QFS)\n",
       "\n",
       "QFS aims to generate summaries that are relevant and responsive to a specific query. Here's a breakdown of the process:\n",
       "\n",
       "**1. Understanding the Query:**\n",
       "\n",
       "* Analyze the query to identify key concepts, entities, and relationships.\n",
       "* Use techniques like named entity recognition and relation extraction to extract relevant information.\n",
       "\n",
       "**2. Retrieval and Ranking:**\n",
       "\n",
       "* Retrieve relevant documents or passages from a knowledge base or corpus.\n",
       "* Rank the retrieved documents based on their relevance to the query. This can involve techniques like keyword matching, semantic similarity, or neural ranking models.\n",
       "\n",
       "**3. Summarization:**\n",
       "\n",
       "* Generate a summary of the retrieved documents that is focused on the query.\n",
       "* This can involve techniques like sentence extraction, abstractive summarization, or a combination of both.\n",
       "* Ensure the summary is concise, informative, and responsive to the query.\n",
       "\n",
       "**4. Evaluation:**\n",
       "\n",
       "* Evaluate the generated summary for its relevance, informativeness, and responsiveness to the query.\n",
       "* Use metrics like ROUGE, BLEU, or human evaluation to assess the quality of the summary.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "* **Domain-specific knowledge:** Incorporate domain-specific knowledge to improve the accuracy and relevance of the summary.\n",
       "* **User preferences:** Consider user preferences for summary length, style, and level of detail.\n",
       "* **Explainability:** Provide explanations for how the summary was generated and why certain information was included or excluded.\n",
       "\n",
       "**Resources:**\n",
       "\n",
       "* **Unified retrieval and reasoning for solving multi-hop question answering over knowledge graph:** This paper discusses a method for multi-hop question answering over knowledge graphs, which can be helpful for retrieving relevant information for QFS.\n",
       "* **Graph retrieval-augmented generation:** This survey provides an overview of graph-based approaches for text generation, which can be useful for generating summaries that are more structured and informative.\n",
       "* **Dense passage retrieval:** This paper discusses dense passage retrieval, which can be used to efficiently retrieve relevant passages for QFS.\n",
       "* **LLMs for summarization:** Large language models (LLMs) can be used for abstractive summarization, which can generate more fluent and informative summaries.\n",
       "\n",
       "By following these steps and considering the additional factors, you can effectively perform Query-Focused Summarization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=False, \n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"How to do Query-Focused Summarization (QFS)?\",\n",
    ")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I am sorry, but the context provided does not contain information on how to make fried rice. The context focuses on knowledge sequences related to generative approaches and discriminative models. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=False,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"How to make fried rice?\",\n",
    ")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"graph-rag.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17ef1fad7b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "# Get the networkx graph\n",
    "g = index.get_networkx_graph()\n",
    "\n",
    "# Create the Pyvis network\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "\n",
    "# Load the networkx graph into the Pyvis network\n",
    "net.from_nx(g)\n",
    "\n",
    "# Generate HTML content\n",
    "html_content = net.generate_html()\n",
    "\n",
    "# Write the HTML content to a file with UTF-8 encoding\n",
    "with open(\"graph-rag.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "# Display the generated HTML file in the notebook\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"graph-rag.html\", width=900, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
